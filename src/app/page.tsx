"use client";

import { useState, useEffect, useRef, useCallback } from "react";
import dynamic from "next/dynamic";
import Header from "./components/Header";
import IntroSection from "./components/Sections/IntroSection";
import WorksSection from "./components/Sections/WorksSection";
import SkillsSection from "./components/Sections/SkillsSection";
import AboutSection from "./components/Sections/AboutSection";
import SpeechBubble from "./components/SpeechBubble";
import VoiceToggle from "./components/VoiceToggle";

const VOICEVOX_ENDPOINT =
  process.env.NEXT_PUBLIC_VOICEVOX_ENDPOINT ?? "http://localhost:50021";
const Live2DCharacter = dynamic(() => import("./components/Live2DCharacter"), {
  ssr: false,
});

type Section = "intro" | "works" | "skills" | "about";

interface SectionDialogue {
  text: string;
  armPose: number;
}

interface AudioCache {
  [key: string]: Blob;
}

export default function Home() {
  const [currentSection, setCurrentSection] = useState<Section>("intro");
  const [voiceEnabled, setVoiceEnabled] = useState(false);
  const [speechText, setSpeechText] = useState("");
  const [showSpeech, setShowSpeech] = useState(false);
  const [isGeneratingVoice, setIsGeneratingVoice] = useState(false);

  const modelRef = useRef<any>(null);
  const audioRef = useRef<HTMLAudioElement | null>(null);
  const mouthAnimationRef = useRef<number | null>(null);
  const abortControllerRef = useRef<AbortController | null>(null);
  const isPlayingRef = useRef(false);
  const isSpeakingRef = useRef(false);
  const isWorkSpeechRef = useRef(false);
  const hasPlayedIntroVoiceRef = useRef(false);

  //  éŸ³å£°ã‚­ãƒ£ãƒƒã‚·ãƒ¥
  const audioCacheRef = useRef<AudioCache>({});
  const isPrecachingRef = useRef(false);

  // ã‚»ã‚¯ã‚·ãƒ§ãƒ³åˆ¥å°è©
  const sectionDialogues: Record<Section, SectionDialogue> = {
    intro: {
      text: "ã“ã‚“ã«ã¡ã¯ãªã®ã ï¼\nãšã‚“ã ã‚‚ã‚“ã¨ä¸€ç·’ã«è¦‹ã¦ã„ãã®ã !\nã“ã®ã‚µã‚¤ãƒˆã¯PCè¦–è´å°‚ç”¨ãªã®ã \n éŸ³å£°ã‚’èããŸã„å ´åˆã¯ğŸ”ŠéŸ³å£°ãƒœã‚¿ãƒ³ã‚’ONã«ã™ã‚‹ã®ã !",
      armPose: 1.0,
    },
    works: {
      text: "ä½œå“ä¸€è¦§ãªã®ã ï¼\næ°—ã«ãªã‚‹ã‚‚ã®ã‚’ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã®ã !",
      armPose: 0.5,
    },
    skills: {
      text: "ä½¿ãˆã‚‹æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯ã‚’ç´¹ä»‹ã™ã‚‹ã®ã ï¼\næ°—ã«ãªã‚‹ã‚‚ã®ã‚’ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã®ã !",
      armPose: 0.0,
    },
    about: {
      text: "QAã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã¨ã—ã¦2å¹´ä»¥ä¸Šã®çµŒé¨“ãŒã‚ã£ã¦ã€ãƒ•ãƒ­ãƒ³ãƒˆã‹ã‚‰ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã€ãƒ†ã‚¹ãƒˆã¾ã§å¯¾å¿œã§ãã‚‹ã®ã ã€‚Reactã‚„Next.jsã§ã®Webé–‹ç™ºã¨ã€Pythonã‚„Node.jsã§ã®ãƒ†ã‚¹ãƒˆè‡ªå‹•åŒ–ã‚’å­¦ã³ãªãŒã‚‰ã€UIã‚„ä½¿ã„ã‚„ã™ã•ã«ã‚‚ã“ã ã‚ã£ã¦ã‚‹ã®ã !æœ€è¿‘ã¯ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚„Live2Dã«ã‚‚æŒ‘æˆ¦ä¸­ãªã®ã !",
      armPose: 0.5,
    },
  };

  const skillSpeechMap = {
    frontend: `ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ãªã®ã !ã¾ãšHTMLã§æ§‹é€ ã‚’ä½œã£ã¦ã€CSSã§è¦‹ãŸç›®ã‚’æ•´ãˆã‚‹ã®ã ã€‚JavaScriptã§å‹•ãã‚’ã¤ã‘ã¦ã€Reactã‚„Next.jsã§ç”»é¢ã‚’åŠ¹ç‡ã‚ˆãçµ„ã¿ç«‹ã¦ã¦ã‚‹ã®ã !TypeScriptã§å®‰å…¨ã«é–‹ç™ºã—ã¦ã€Tailwind CSSã§ã‚¹ã‚¿ã‚¤ãƒ«ã‚’ç®¡ç†ã—ã¦ã‚‹ã®ã ã€‚å¿…è¦ã«å¿œã˜ã¦jQueryã‚‚ä½¿ã†ã®ã !`,
    backend: `ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãªã®ã !Node.jsã‚„Pythonã€PHPã‚’ä½¿ã£ã¦ã€ã‚µãƒ¼ãƒãƒ¼å´ã®å‡¦ç†ã‚’æ›¸ãã®ã ã€‚FastAPIã§é«˜é€ŸãªAPIã‚’ä½œã£ã¦ã€ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã¨é€£æºã—ãŸã‚Šã—ã¦ã‚‹ã®ã ã€‚Supabaseã‚’ä½¿ã£ã¦ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚„èªè¨¼ã‚‚ã¾ã¨ã‚ã¦ç®¡ç†ã—ã¦ã‚‹ã®ã ï¼`,
    devops: `é–‹ç™ºã‚’æ”¯ãˆã‚‹æŠ€è¡“ãŸã¡ãªã®ã ! Dockerã§é–‹ç™ºç’°å¢ƒã‚’ãã‚ãˆã¦ã€èª°ã§ã‚‚åŒã˜ç’°å¢ƒã§å‹•ã‹ã›ã‚‹ã‚ˆã†ã«ã™ã‚‹ã®ã ã€‚GitHubã§ã‚³ãƒ¼ãƒ‰ã‚’ç®¡ç†ã—ã¦ã€Playwrightã‚„Seleniumã§ãƒ†ã‚¹ãƒˆã‚’è‡ªå‹•åŒ–! ãƒ‡ãƒ—ãƒ­ã‚¤ã¯ä¸»ã«Vercelã¨Renderãªã®ã !`,
  } as const;

  const LOCAL_VOICEVOX =
    process.env.NEXT_PUBLIC_VOICEVOX_ENDPOINT ?? "http://localhost:50021";

  const REMOTE_VOICEVOX = "https://deprecatedapis.tts.quest/v2/voicevox/audio/";

  const VOICEVOX_API_KEY = process.env.NEXT_PUBLIC_VOICEVOX_API_KEY;

  // ãƒ­ãƒ¼ã‚«ãƒ«ãŒç”Ÿãã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
  const checkLocalVoicevox = async (): Promise<boolean> => {
    try {
      const res = await fetch(`${LOCAL_VOICEVOX}/speakers`, { method: "GET" });
      return res.ok;
    } catch {
      return false;
    }
  };

  // -------------------------
  // ç™ºè©±ã®å³ã‚­ãƒ£ãƒ³ã‚»ãƒ«
  // -------------------------
  const cancelCurrentSpeech = useCallback(() => {
    abortControllerRef.current?.abort();
    abortControllerRef.current = null;

    if (audioRef.current) {
      audioRef.current.pause();
      audioRef.current.currentTime = 0;
      audioRef.current = null;
    }

    if (mouthAnimationRef.current) {
      clearInterval(mouthAnimationRef.current);
      mouthAnimationRef.current = null;
    }

    modelRef.current?.internalModel?.coreModel?.setParameterValueById(
      "ParamMouthOpen",
      0,
    );

    isPlayingRef.current = false;
    setShowSpeech(false);
    setIsGeneratingVoice(false);
  }, []);

  // Live2D ready
  const handleModelReady = useCallback((model: any) => {
    modelRef.current = model;
  }, []);

  const setParameter = useCallback((id: string, value: number) => {
    modelRef.current?.internalModel?.coreModel?.setParameterValueById(
      id,
      value,
    );
  }, []);

  const startMouthAnimation = useCallback(() => {
    let toggle = true;
    mouthAnimationRef.current = window.setInterval(() => {
      setParameter("ParamMouthOpen", toggle ? 0.8 : 0.2);
      toggle = !toggle;
    }, 150);
  }, [setParameter]);

  const stopMouthAnimation = useCallback(() => {
    if (mouthAnimationRef.current) {
      clearInterval(mouthAnimationRef.current);
      mouthAnimationRef.current = null;
    }
    setParameter("ParamMouthOpen", 0);
  }, [setParameter]);

  // -------------------------
  //  éŸ³å£°ç”Ÿæˆï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚ã‚Šï¼‰
  // -------------------------
  const generateVoiceBlob = useCallback(
    async (text: string, cacheKey?: string): Promise<Blob | null> => {
      if (cacheKey && audioCacheRef.current[cacheKey]) {
        return audioCacheRef.current[cacheKey];
      }

      const controller = new AbortController();
      abortControllerRef.current = controller;

      try {
        const useLocal: boolean = await checkLocalVoicevox();

        // =========================
        // ãƒ­ãƒ¼ã‚«ãƒ« VOICEVOX
        // =========================
        if (useLocal) {
          const queryRes = await fetch(
            `${LOCAL_VOICEVOX}/audio_query?text=${encodeURIComponent(text)}&speaker=1`,
            { method: "POST", signal: controller.signal },
          );
          if (!queryRes.ok) throw new Error("local audio_query failed");

          const query = await queryRes.json();

          const synthRes = await fetch(
            `${LOCAL_VOICEVOX}/synthesis?speaker=1`,
            {
              method: "POST",
              headers: { "Content-Type": "application/json" },
              body: JSON.stringify(query),
              signal: controller.signal,
            },
          );
          if (!synthRes.ok) throw new Error("local synthesis failed");

          const blob = await synthRes.blob();
          if (cacheKey) audioCacheRef.current[cacheKey] = blob;
          return blob;
        }

        // =========================
        // ãƒªãƒ¢ãƒ¼ãƒˆ VOICEVOXï¼ˆtts.questï¼‰
        // =========================
        const params = new URLSearchParams({
          key: VOICEVOX_API_KEY ?? "",
          text,
          speaker: "1",
          pitch: "0",
          intonationScale: "1",
          speed: "1",
        });

        const remoteRes = await fetch(
          `${REMOTE_VOICEVOX}?${params.toString()}`,
          {
            method: "GET",
            signal: controller.signal,
          },
        );

        if (!remoteRes.ok) {
          const msg = await remoteRes.text();
          throw new Error(`remote voicevox failed: ${msg}`);
        }

        const arrayBuffer = await remoteRes.arrayBuffer();
        const blob = new Blob([arrayBuffer], { type: "audio/wav" });

        if (cacheKey) {
          audioCacheRef.current[cacheKey] = blob;
        }

        return blob;
      } catch (e) {
        if (controller.signal.aborted) {
          console.log("Voice generation aborted");
        } else {
          console.error("Voice generation error:", e);
        }
        return null;
      } finally {
        abortControllerRef.current = null;
      }
    },
    [],
  );  

  // -------------------------
  //  éŸ³å£°å†ç”Ÿ
  // -------------------------
  const speakWithVoicevox = useCallback(
    async (text: string, cacheKey?: string) => {
      if (!voiceEnabled) return;

      cancelCurrentSpeech();
      isPlayingRef.current = true;
      setIsGeneratingVoice(true);

      try {
        const blob = await generateVoiceBlob(text, cacheKey);

        if (!blob) {
          setIsGeneratingVoice(false);
          isPlayingRef.current = false;
          return;
        }

        // Audioè¦ç´ ã‚’ä½œæˆ
        const audio = new Audio();
        audioRef.current = audio;

        audio.onplay = () => {
          setIsGeneratingVoice(false);
          startMouthAnimation();
        };

        audio.onended = () => {
          stopMouthAnimation();
          isPlayingRef.current = false;
          isSpeakingRef.current = false;
          if (audio.src) URL.revokeObjectURL(audio.src);
        };

        audio.onerror = () => {
          console.error("Audio playback error");
          setIsGeneratingVoice(false);
          isPlayingRef.current = false;
        };

        // Blob URLã‚’ä½œæˆã—ã¦å³åº§ã«å†ç”Ÿ
        audio.src = URL.createObjectURL(blob);
        await audio.play();
      } catch (e: any) {
        console.error("Speech error:", e);
        setIsGeneratingVoice(false);
        isPlayingRef.current = false;
      }
    },
    [
      voiceEnabled,
      cancelCurrentSpeech,
      generateVoiceBlob,
      startMouthAnimation,
      stopMouthAnimation,
    ],
  );

  // -------------------------
  //  ã‚»ã‚¯ã‚·ãƒ§ãƒ³éŸ³å£°ã®ãƒ—ãƒªãƒ­ãƒ¼ãƒ‰
  // -------------------------
  const precacheSectionVoices = useCallback(async () => {
    if (isPrecachingRef.current) return;
    if (!voiceEnabled) return;

    isPrecachingRef.current = true;
    console.log("ğŸ”Š Precaching section voices...");

    const sections: Section[] = ["intro", "works", "skills", "about"];

    for (const section of sections) {
      const text = sectionDialogues[section].text;
      const cacheKey = `section_${section}`;

      // ã™ã§ã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚Œã¦ã„ã‚Œã°ã‚¹ã‚­ãƒƒãƒ—
      if (audioCacheRef.current[cacheKey]) continue;

      try {
        await generateVoiceBlob(text, cacheKey);
        console.log(`âœ“ Cached: ${section}`);
      } catch (e) {
        console.error(`Failed to cache ${section}:`, e);
      }
    }

    console.log("âœ“ Precaching complete!");
    isPrecachingRef.current = false;
  }, [voiceEnabled, sectionDialogues, generateVoiceBlob]);

  // -------------------------
  // ã‚»ã‚¯ã‚·ãƒ§ãƒ³å¤‰æ›´
  // -------------------------
  const handleSectionChange = useCallback(
    (section: Section) => {
      if (currentSection === section) return;

      cancelCurrentSpeech();
      setCurrentSection(section);

      const d = sectionDialogues[section];
      setParameter("ParamArmR", d.armPose);
      setSpeechText(d.text);
      setShowSpeech(true);

      // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ã‚’æŒ‡å®šã—ã¦å†ç”Ÿ
      speakWithVoicevox(d.text, `section_${section}`);
    },
    [
      currentSection,
      cancelCurrentSpeech,
      sectionDialogues,
      speakWithVoicevox,
      setParameter,
    ],
  );

  // -------------------------
  // Worksã‚¯ãƒªãƒƒã‚¯
  // -------------------------
  const handleWorkClick = useCallback(
    (work: { title: string; description: string }) => {
      setParameter("ParamArmR", 1.0);
      isSpeakingRef.current = true;

      cancelCurrentSpeech();

      const text = `${work.title}ãªã®ã ï¼\n${work.description}`;

      setSpeechText(text);
      setShowSpeech(true);
      speakWithVoicevox(text);
    },
    [cancelCurrentSpeech, speakWithVoicevox, setParameter],
  );

  // -------------------------
  // Skillã‚¯ãƒªãƒƒã‚¯
  // -------------------------
  const handleSkillClick = useCallback(
    (type: "frontend" | "backend" | "devops") => {
      const text = skillSpeechMap[type];

      setParameter("ParamArmR", 1.0);
      isSpeakingRef.current = true;

      cancelCurrentSpeech();
      setSpeechText(text);
      setShowSpeech(true);

      // ã‚¹ã‚­ãƒ«ã‚‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥
      speakWithVoicevox(text, `skill_${type}`);
    },
    [cancelCurrentSpeech, speakWithVoicevox, setParameter],
  );

  // -------------------------
  // scrollç›£è¦–
  // -------------------------
  useEffect(() => {
    const onScroll = () => {
      if (isWorkSpeechRef.current) return;

      const center = window.scrollY + window.innerHeight / 2;
      const idx = Math.floor(center / window.innerHeight);

      const sections: Section[] = ["intro", "works", "skills", "about"];
      const s = sections[Math.min(idx, sections.length - 1)];

      if (s !== currentSection) {
        handleSectionChange(s);
      }
    };

    window.addEventListener("scroll", onScroll);
    return () => window.removeEventListener("scroll", onScroll);
  }, [currentSection, handleSectionChange]);

  // -------------------------
  //  éŸ³å£°ONã«ãªã£ãŸã‚‰ãƒ—ãƒªãƒ­ãƒ¼ãƒ‰é–‹å§‹
  // -------------------------
  useEffect(() => {
    if (voiceEnabled) {
      // ãƒ—ãƒªãƒ­ãƒ¼ãƒ‰ã‚’é–‹å§‹ï¼ˆéåŒæœŸï¼‰
      precacheSectionVoices();

      // introéŸ³å£°ã‚’å†ç”Ÿï¼ˆåˆå›ã®ã¿ï¼‰
      if (!hasPlayedIntroVoiceRef.current && currentSection === "intro") {
        hasPlayedIntroVoiceRef.current = true;
        speakWithVoicevox(sectionDialogues.intro.text, "section_intro");
      }
    }
  }, [
    voiceEnabled,
    currentSection,
    precacheSectionVoices,
    speakWithVoicevox,
    sectionDialogues,
  ]);

  // -------------------------
  // åˆå›ãƒã‚¦ãƒ³ãƒˆæ™‚ intro å¹ãå‡ºã—è¡¨ç¤º
  // -------------------------
  useEffect(() => {
    const d = sectionDialogues.intro;

    setParameter("ParamArmR", d.armPose);
    setSpeechText(d.text);
    setShowSpeech(true);
    // eslint-disable-next-line react-hooks/exhaustive-deps
  }, []);

  return (
    <>
      <Header />
      <VoiceToggle
        enabled={voiceEnabled}
        onToggle={() => setVoiceEnabled((v) => !v)}
      />

      {/*  ã‚ªãƒ—ã‚·ãƒ§ãƒ³: éŸ³å£°ç”Ÿæˆä¸­ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼ */}
      {isGeneratingVoice && (
        <div className="fixed top-20 right-4 bg-blue-500 text-white px-4 py-2 rounded-full text-sm shadow-lg z-50 flex items-center gap-2">
          <div className="w-4 h-4 border-2 border-white border-t-transparent rounded-full animate-spin" />
          éŸ³å£°ç”Ÿæˆä¸­...
        </div>
      )}

      <main>
        <IntroSection />
        <WorksSection onWorkClick={handleWorkClick} />
        <SkillsSection onSkillClick={handleSkillClick} />
        <AboutSection />
      </main>

      <Live2DCharacter
        onReady={handleModelReady}
        currentSection={currentSection}
      />

      <SpeechBubble
        text={speechText}
        visible={showSpeech}
        onComplete={() => {
          setShowSpeech(false);
          isSpeakingRef.current = false;
        }}
      />
    </>
  );
}
